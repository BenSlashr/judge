# SEO Keyword Classifier

Un outil avancÃ© d'analyse et de clustering de mots-clÃ©s SEO avec intelligence artificielle.

## ğŸš€ FonctionnalitÃ©s

- **Import de fichiers** : CSV et XLSX jusqu'Ã  50 000 mots-clÃ©s
- **Enrichissement automatique** : Volume de recherche, CPC, difficultÃ© (Google Ads, Semrush)
- **Clustering intelligent** : Utilise des embeddings sÃ©mantiques et l'analyse SERP
- **Nommage IA** : Attribution automatique de noms aux clusters via GPT-4
- **Visualisation UMAP** : ReprÃ©sentation graphique des clusters
- **Export multiple** : CSV, Excel, JSON
- **Interface moderne** : Design professionnel avec Tailwind CSS
- **Traitement asynchrone** : Suivi en temps rÃ©el avec Celery

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ main.py              # Application FastAPI principale
â”œâ”€â”€ config.py            # Configuration et chiffrement
â”œâ”€â”€ models.py            # ModÃ¨les Pydantic
â”œâ”€â”€ database.py          # Gestion SQLite
â”œâ”€â”€ celery_app.py        # Configuration Celery
â”œâ”€â”€ tasks.py             # TÃ¢ches asynchrones
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ enrichment.py    # Enrichissement SEO
â”‚   â””â”€â”€ clustering.py    # Clustering et IA
â””â”€â”€ utils/
    â””â”€â”€ file_processing.py  # Traitement de fichiers
```

## ğŸš€ Installation rapide

```bash
# 1. Cloner le projet
git clone <votre-repo>
cd seo-keyword-classifier

# 2. Installer les dÃ©pendances
pip install -r requirements.txt

# 3. Configuration
cp env.example .env
# Ã‰ditez .env avec vos clÃ©s API

# 4. DÃ©marrer Redis
redis-server

# 5. DÃ©marrer Celery
celery -A app.celery_app worker --loglevel=info

# 6. DÃ©marrer l'application
uvicorn app.main:app --reload
```

## âš™ï¸ Configuration

### Variables d'environnement

Copiez `env.example` vers `.env` et configurez vos clÃ©s API :

```bash
# DataForSEO (obligatoire pour la SERP)
DATAFOR_SEO_LOGIN=votre_login_dataforseo
DATAFOR_SEO_PASSWORD=votre_password_dataforseo

# OpenAI (obligatoire pour le nommage intelligent)
OPENAI_API_KEY=votre_cle_openai

# Google Ads (optionnel)
GOOGLE_ADS_DEVELOPER_TOKEN=votre_token
# ... autres clÃ©s Google Ads
```

### SÃ©curitÃ©

- Le fichier `.env` contient vos secrets et ne doit **jamais** Ãªtre committÃ©
- Assurez-vous que `.env` est dans votre `.gitignore`
- En production, utilisez des variables d'environnement systÃ¨me ou un gestionnaire de secrets

**Pourquoi pas de chiffrement ?**
- `.env` est dÃ©jÃ  le standard de l'industrie
- Le chiffrement local n'ajoute pas de sÃ©curitÃ© rÃ©elle
- Plus simple = moins d'erreurs

## ğŸ“Š Utilisation

### 1. Upload de fichiers

- Formats supportÃ©s : CSV, XLSX
- Colonne requise : `keyword` (ou variantes : `keywords`, `mot-clÃ©`, etc.)
- Limite : 50 000 mots-clÃ©s par fichier

### 2. Configuration des paramÃ¨tres

- **Mode SERP** : 
  - `None` : Clustering uniquement par embeddings
  - `Pivot only` : SERP seulement pour les mots-clÃ©s pivots
  - `Full SERP` : SERP pour tous les mots-clÃ©s
  
- **Alpha** : Poids entre embeddings (1.0) et SERP (0.0)
- **Algorithme** : HDBSCAN, AgglomÃ©ratif, ou Louvain
- **Taille min cluster** : Nombre minimum de mots-clÃ©s par cluster

### 3. Suivi et rÃ©sultats

- Suivi en temps rÃ©el de la progression
- Visualisation UMAP des clusters
- Export dans le format choisi
- Historique des analyses

## ğŸ”§ API

### Endpoints principaux

- `POST /api/jobs` : CrÃ©er une nouvelle analyse
- `GET /api/jobs/{job_id}` : Statut d'un job
- `GET /api/jobs/{job_id}/result` : TÃ©lÃ©charger les rÃ©sultats
- `GET /api/jobs` : Liste des jobs rÃ©cents
- `GET /api/jobs/{job_id}/visualization` : DonnÃ©es de visualisation

### Exemple d'utilisation

```python
import requests

# CrÃ©er un job
files = {'file': open('keywords.csv', 'rb')}
params = {
    'serp_mode': 'pivot_only',
    'clustering_algorithm': 'hdbscan',
    'min_cluster_size': 5,
    'export_format': 'xlsx'
}

response = requests.post(
    'http://localhost:8000/api/jobs',
    files=files,
    data={'parameters': json.dumps(params)}
)

job_id = response.json()['job_id']

# Suivre la progression
while True:
    status = requests.get(f'http://localhost:8000/api/jobs/{job_id}').json()
    if status['state'] == 'completed':
        break
    time.sleep(5)

# TÃ©lÃ©charger les rÃ©sultats
results = requests.get(f'http://localhost:8000/api/jobs/{job_id}/result')
```

## ğŸ§ª Tests

```bash
# Tests unitaires
pytest

# Tests avec couverture
pytest --cov=app

# Tests end-to-end (Playwright)
pytest tests/e2e/
```

## ğŸ“ˆ Performance

### Benchmarks typiques

- **Mode embeddings uniquement** : ~1000 mots-clÃ©s/minute
- **Mode SERP pivot** : ~500 mots-clÃ©s/minute  
- **Mode SERP complet** : ~300 mots-clÃ©s/minute

### Optimisations

- Cache SERP avec TTL configurable
- Traitement par batches
- RÃ©duction dimensionnelle UMAP pour >5000 mots-clÃ©s
- ParallÃ©lisation du scraping SERP

## ğŸ”’ SÃ©curitÃ©

- Chiffrement des clÃ©s API avec Fernet
- HTTPS obligatoire en production
- Validation stricte des entrÃ©es
- Isolation des processus avec Celery

## ğŸ³ DÃ©ploiement

### Production avec Docker

```bash
# Variables d'environnement de production
export ENVIRONMENT=production
export SECRET_KEY=your-production-secret-key

# DÃ©ploiement
docker-compose -f docker-compose.prod.yml up -d
```

### Monitoring

- Logs structurÃ©s dans `/app/logs`
- MÃ©triques Celery via Flower
- Health checks sur `/health`
- Statistiques sur `/api/stats`

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request

## ğŸ“ Licence

DistribuÃ© sous licence MIT. Voir `LICENSE` pour plus d'informations.

## ğŸ†˜ Support

- ğŸ“§ Email : support@example.com
- ğŸ“– Documentation : [docs.example.com](https://docs.example.com)
- ğŸ› Issues : [GitHub Issues](https://github.com/example/issues)

---

**DÃ©veloppÃ© avec â¤ï¸ pour l'optimisation SEO** 
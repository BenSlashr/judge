import os
import uuid
import logging
from datetime import datetime
from typing import List, Optional
from pathlib import Path

from fastapi import FastAPI, File, UploadFile, Form, HTTPException, Depends, Query
from fastapi.responses import FileResponse, HTMLResponse
from fastapi.staticfiles import StaticFiles
from fastapi.templating import Jinja2Templates
from fastapi.middleware.cors import CORSMiddleware
from fastapi.middleware.trustedhost import TrustedHostMiddleware
from starlette.requests import Request
from starlette.middleware.base import BaseHTTPMiddleware

from app.config import settings
from app.models import (
    JobParameters, JobProgress, JobResult, JobSummary, 
    JobStatus, UMAPVisualization, Keyword, Cluster
)
from app.database import db_manager
from app.celery_app import celery_app
# Import des t√¢ches fait de mani√®re lazy pour √©viter les imports circulaires

# Configuration du logging
logging.basicConfig(
    level=logging.DEBUG,  # Chang√© temporairement pour plus de d√©tails
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Initialisation de l'application FastAPI
app = FastAPI(
    title="SEO Keyword Classifier",
    description="Outil d'analyse et de clustering de mots-cl√©s SEO",
    version="1.0.0",
    root_path=settings.root_path
)

# Configuration CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # En production, sp√©cifier les domaines autoris√©s
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Middleware pour g√©rer les headers de proxy
class ProxyHeadersMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # Traite les headers X-Forwarded-* pour les reverse proxies
        if "X-Forwarded-Proto" in request.headers:
            request.scope["scheme"] = request.headers["X-Forwarded-Proto"]
        if "X-Forwarded-Host" in request.headers:
            request.scope["server"] = (request.headers["X-Forwarded-Host"], 443 if request.scope["scheme"] == "https" else 80)
        
        response = await call_next(request)
        return response

app.add_middleware(ProxyHeadersMiddleware)

# Configuration des fichiers statiques et templates
static_dir = Path("static")
static_dir.mkdir(exist_ok=True)

templates_dir = Path("templates")
templates_dir.mkdir(exist_ok=True)

app.mount("/static", StaticFiles(directory="static"), name="static")
templates = Jinja2Templates(directory="templates")

# R√©pertoires de donn√©es
Path("data/uploads").mkdir(parents=True, exist_ok=True)
Path("data/exports").mkdir(parents=True, exist_ok=True)

@app.on_event("startup")
async def startup_event():
    """√âv√©nement de d√©marrage de l'application"""
    logger.info("D√©marrage de l'application SEO Keyword Classifier")
    
    # Test de connexion Redis
    try:
        # Test de ping Redis
        inspect = celery_app.control.inspect()
        active_workers = inspect.active()
        logger.info(f"‚úÖ Connexion Redis OK - Workers actifs: {active_workers}")
    except Exception as e:
        logger.error(f"‚ùå Erreur connexion Redis: {e}")
    
    # Initialise la base de donn√©es
    db_manager._init_tables()
    
    # Nettoie le cache expir√© au d√©marrage
    db_manager.cleanup_expired_cache()
    
    logger.info(f"üöÄ Application d√©marr√©e avec ROOT_PATH: '{settings.root_path}'")

@app.on_event("shutdown")
async def shutdown_event():
    """√âv√©nement d'arr√™t de l'application"""
    logger.info("Arr√™t de l'application")

# ===== ROUTES WEB =====

@app.get("/", response_class=HTMLResponse)
async def home(request: Request):
    """Page d'accueil avec interface d'upload"""
    return templates.TemplateResponse("index.html", {
        "request": request,
        "root_path": settings.root_path
    })

@app.get("/parameters", response_class=HTMLResponse)
async def parameters_page(request: Request):
    """Page de configuration des param√®tres"""
    return templates.TemplateResponse("parameters.html", {
        "request": request,
        "root_path": settings.root_path
    })

@app.get("/progress/{job_id}", response_class=HTMLResponse)
async def progress_page(request: Request, job_id: str):
    """Page de suivi de progression"""
    return templates.TemplateResponse("progress.html", {
        "request": request, 
        "job_id": job_id,
        "root_path": settings.root_path
    })

@app.get("/results/{job_id}", response_class=HTMLResponse)
async def results_page(request: Request, job_id: str):
    """Page d'affichage des r√©sultats"""
    return templates.TemplateResponse("results.html", {
        "request": request, 
        "job_id": job_id,
        "root_path": settings.root_path
    })

@app.get("/history", response_class=HTMLResponse)
async def history_page(request: Request):
    """Page d'historique des jobs"""
    return templates.TemplateResponse("history.html", {
        "request": request,
        "root_path": settings.root_path
    })

@app.get("/test-links", response_class=HTMLResponse)
async def test_links_page(request: Request):
    """Page de test pour v√©rifier tous les liens avec root_path"""
    return templates.TemplateResponse("test_links.html", {
        "request": request,
        "root_path": settings.root_path
    })

@app.get("/test-celery")
async def test_celery():
    """Test de fonctionnement de Celery"""
    try:
        # Import lazy pour √©viter les probl√®mes d'import circulaire
        from app.tasks import ping_task, test_task
        
        # Test de ping simple
        ping_result = ping_task.delay()
        logger.info(f"T√¢che ping lanc√©e: {ping_result.id}")
        
        # Test avec log
        test_result = test_task.delay()
        logger.info(f"T√¢che test lanc√©e: {test_result.id}")
        
        # Essaie de r√©cup√©rer le r√©sultat (avec timeout)
        try:
            ping_value = ping_result.get(timeout=10)
            test_value = test_result.get(timeout=10)
            
            return {
                "status": "success",
                "ping_task_id": ping_result.id,
                "ping_result": ping_value,
                "test_task_id": test_result.id,
                "test_result": test_value,
                "message": "Celery fonctionne correctement!"
            }
        except Exception as timeout_error:
            return {
                "status": "timeout",
                "ping_task_id": ping_result.id,
                "test_task_id": test_result.id,
                "error": str(timeout_error),
                "message": "Les t√¢ches ont √©t√© cr√©√©es mais n'ont pas √©t√© trait√©es dans les temps"
            }
            
    except Exception as e:
        logger.error(f"Erreur test Celery: {e}")
        return {
            "status": "error",
            "error": str(e),
            "message": "Erreur lors du test Celery"
        }

@app.get("/test-celery-simple")
async def test_celery_simple():
    """Test de communication avec Celery avec t√¢ches simples"""
    logger.info("üß™ Test des t√¢ches Celery simples")
    
    try:
        # Import des t√¢ches de fa√ßon lazy
        from app.tasks import ping_task, test_task
        
        # Test ping
        logger.info("üì§ Lancement t√¢che ping...")
        ping_result = ping_task.delay()
        logger.info(f"üéØ T√¢che ping cr√©√©e: {ping_result.id}")
        
        # Attendre 5 secondes max
        try:
            ping_response = ping_result.get(timeout=5)
            logger.info(f"‚úÖ Ping re√ßu: {ping_response}")
        except Exception as e:
            logger.error(f"‚ùå Ping timeout: {e}")
            ping_response = f"TIMEOUT: {e}"
        
        # Test t√¢che simple
        logger.info("üì§ Lancement t√¢che test...")
        test_result = test_task.delay()
        logger.info(f"üéØ T√¢che test cr√©√©e: {test_result.id}")
        
        try:
            test_response = test_result.get(timeout=5)
            logger.info(f"‚úÖ Test re√ßu: {test_response}")
        except Exception as e:
            logger.error(f"‚ùå Test timeout: {e}")
            test_response = f"TIMEOUT: {e}"
        
        return {
            "ping_task_id": ping_result.id,
            "ping_result": ping_response,
            "test_task_id": test_result.id,
            "test_result": test_response
        }
        
    except Exception as e:
        logger.error(f"‚ùå Erreur test Celery: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Erreur test Celery: {str(e)}")

# ===== API ENDPOINTS =====

@app.post("/api/jobs")
async def create_job(
    file: UploadFile = File(...),
    parameters: str = Form(...)
):
    """Cr√©e un nouveau job d'analyse de mots-cl√©s"""
    
    try:
        # Parse les param√®tres JSON
        import json
        params_dict = json.loads(parameters)
        job_parameters = JobParameters(**params_dict)
        
        # G√©n√®re un ID unique pour le job
        job_id = str(uuid.uuid4())
        
        # Sauvegarde le fichier upload√©
        upload_dir = Path("data/uploads")
        file_path = upload_dir / f"{job_id}_{file.filename}"
        
        with open(file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        logger.info(f"Fichier sauvegard√©: {file_path}")
        
        # Validation rapide du fichier pour compter les mots-cl√©s
        from app.utils.file_processing import process_uploaded_file
        keywords = process_uploaded_file(str(file_path))
        
        # Cr√©e le job en base
        db_manager.create_job(job_id, job_parameters, len(keywords))
        
        # Lance la t√¢che asynchrone
        from app.tasks import process_keywords_task
        task = process_keywords_task.delay(
            job_id=job_id,
            file_path=str(file_path),
            parameters_dict=params_dict
        )
        
        logger.info(f"Job {job_id} cr√©√© et t√¢che lanc√©e: {task.id}")
        
        return {"job_id": job_id}
        
    except Exception as e:
        logger.error(f"Erreur lors de la cr√©ation du job: {e}")
        raise HTTPException(status_code=400, detail=str(e))

@app.get("/api/jobs/{job_id}")
async def get_job_status(job_id: str) -> JobProgress:
    """R√©cup√®re le statut en temps r√©el d'un job"""
    
    logger.debug(f"üîç Demande de statut pour job {job_id}")
    
    try:
        # R√©cup√®re les infos du job depuis la base
        job_data = db_manager.get_job(job_id)
        
        if not job_data:
            logger.warning(f"‚ùå Job {job_id} non trouv√© en base")
            raise HTTPException(status_code=404, detail="Job non trouv√©")
        
        logger.debug(f"üìä Job {job_id} - Status DB: {job_data['status']}")
        
        # R√©cup√®re l'√©tat de la t√¢che Celery
        task_id = None  # Il faudrait stocker l'ID de t√¢che pour un suivi pr√©cis
        
        # Pour l'instant, on se base sur le statut en base
        status = JobStatus(job_data["status"])
        
        if status == JobStatus.COMPLETED:
            logger.debug(f"‚úÖ Job {job_id} - TERMIN√â")
            progress = JobProgress(
                progress=100.0,
                state=status,
                message="Traitement termin√© avec succ√®s"
            )
        elif status == JobStatus.FAILED:
            logger.debug(f"‚ùå Job {job_id} - √âCHEC: {job_data.get('error_message', 'Erreur inconnue')}")
            progress = JobProgress(
                progress=0.0,
                state=status,
                message=job_data.get("error_message", "Erreur inconnue")
            )
        elif status == JobStatus.PROCESSING:
            logger.debug(f"‚öôÔ∏è Job {job_id} - EN COURS")
            progress = JobProgress(
                progress=50.0,  # Estimation si pas d'info pr√©cise
                state=status,
                message="Traitement en cours..."
            )
        else:  # PENDING
            logger.debug(f"‚è≥ Job {job_id} - EN ATTENTE")
            progress = JobProgress(
                progress=0.0,
                state=status,
                message="En attente de traitement..."
            )
        
        logger.debug(f"üì§ Job {job_id} - R√©ponse: {progress.progress}% - {progress.message}")
        return progress
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"üí• Erreur lors de la r√©cup√©ration du statut du job {job_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/jobs/{job_id}/result")
async def download_job_result(
    job_id: str, 
    format: str = Query("csv", regex="^(csv|xlsx|json)$")
):
    """T√©l√©charge le r√©sultat d'un job"""
    
    try:
        job_data = db_manager.get_job(job_id)
        
        if not job_data:
            raise HTTPException(status_code=404, detail="Job non trouv√©")
        
        if job_data["status"] != JobStatus.COMPLETED:
            raise HTTPException(status_code=400, detail="Job non termin√©")
        
        export_file_path = job_data.get("export_file_path")
        
        if not export_file_path or not os.path.exists(export_file_path):
            raise HTTPException(status_code=404, detail="Fichier de r√©sultat non trouv√©")
        
        # D√©termine le type MIME
        if format == "csv":
            media_type = "text/csv"
        elif format == "xlsx":
            media_type = "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        else:  # json
            media_type = "application/json"
        
        filename = f"keywords_clusters_{job_id}.{format}"
        
        return FileResponse(
            path=export_file_path,
            media_type=media_type,
            filename=filename
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors du t√©l√©chargement du r√©sultat {job_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/jobs")
async def list_jobs(limit: int = Query(10, ge=1, le=100)) -> List[JobSummary]:
    """Liste les derniers jobs"""
    
    try:
        jobs_data = db_manager.get_recent_jobs(limit)
        
        jobs = []
        for job_data in jobs_data:
            # Parse les param√®tres
            import json
            parameters = JobParameters(**json.loads(job_data["parameters"]))
            
            job_summary = JobSummary(
                job_id=job_data["job_id"],
                status=JobStatus(job_data["status"]),
                created_at=datetime.fromisoformat(job_data["created_at"]),
                completed_at=datetime.fromisoformat(job_data["completed_at"]) if job_data["completed_at"] else None,
                keywords_count=job_data["keywords_count"],
                clusters_count=job_data["clusters_count"],
                parameters=parameters
            )
            jobs.append(job_summary)
        
        return jobs
        
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des jobs: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/jobs/{job_id}/details")
async def get_job_details(job_id: str):
    """R√©cup√®re les d√©tails complets d'un job"""
    
    try:
        logger.debug(f"üîç R√©cup√©ration des d√©tails pour job {job_id}")
        
        job_data = db_manager.get_job(job_id)
        
        if not job_data:
            raise HTTPException(status_code=404, detail="Job non trouv√©")
        
        logger.debug(f"üìä Job {job_id} trouv√©: {job_data.get('status')}")
        
        # Parse les param√®tres
        import json
        parameters_data = json.loads(job_data["parameters"])
        logger.debug(f"‚úÖ Param√®tres pars√©s pour job {job_id}")
        
        # R√©cup√®re les mots-cl√©s et clusters si le job est termin√©
        keywords = None
        clusters = None
        
        if job_data["status"] == JobStatus.COMPLETED:
            logger.debug(f"üîÑ R√©cup√©ration des donn√©es pour job termin√© {job_id}")
            
            # R√©cup√®re directement les dictionnaires
            try:
                keywords = db_manager.get_job_keywords(job_id)
                logger.debug(f"üìù {len(keywords) if keywords else 0} mots-cl√©s trouv√©s pour {job_id}")
            except Exception as e:
                logger.error(f"‚ùå Erreur r√©cup√©ration mots-cl√©s {job_id}: {e}")
                keywords = []
            
            try:
                clusters = db_manager.get_job_clusters(job_id)
                logger.debug(f"üîó {len(clusters) if clusters else 0} clusters trouv√©s pour {job_id}")
            except Exception as e:
                logger.error(f"‚ùå Erreur r√©cup√©ration clusters {job_id}: {e}")
                clusters = []
        
        logger.debug(f"üîÑ Cr√©ation de la r√©ponse pour {job_id}")
        
        # Retourne un dictionnaire simple
        result = {
            "job_id": job_data["job_id"],
            "status": job_data["status"],
            "created_at": job_data["created_at"],
            "completed_at": job_data.get("completed_at"),
            "parameters": parameters_data,
            "keywords_count": job_data["keywords_count"],
            "clusters_count": job_data.get("clusters_count"),
            "keywords": keywords,
            "clusters": clusters,
            "export_url": f"/api/jobs/{job_id}/result" if job_data["status"] == JobStatus.COMPLETED else None,
            "error_message": job_data.get("error_message")
        }
        
        logger.debug(f"‚úÖ R√©ponse cr√©√©e pour {job_id}")
        
        return result
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des d√©tails du job {job_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/jobs/{job_id}/visualization")
async def get_job_visualization(job_id: str) -> UMAPVisualization:
    """R√©cup√®re les donn√©es de visualisation UMAP pour un job"""
    
    try:
        job_data = db_manager.get_job(job_id)
        
        if not job_data:
            raise HTTPException(status_code=404, detail="Job non trouv√©")
        
        if job_data["status"] != JobStatus.COMPLETED:
            raise HTTPException(status_code=400, detail="Job non termin√©")
        
        # R√©cup√®re les mots-cl√©s (dictionnaires maintenant)
        keywords_raw = db_manager.get_job_keywords(job_id)
        
        if not keywords_raw:
            raise HTTPException(status_code=404, detail="Aucun mot-cl√© trouv√©")
        
        # G√©n√®re la visualisation (√† impl√©menter selon les besoins)
        # Pour l'instant, on retourne des donn√©es simul√©es
        from app.services.clustering import clustering_service
        
        keyword_texts = [kw["keyword"] for kw in keywords_raw]
        embeddings = clustering_service.generate_embeddings(keyword_texts)
        cluster_labels = [kw.get("cluster_id", -1) for kw in keywords_raw]
        
        visualization = clustering_service.create_umap_visualization(
            embeddings, keyword_texts, cluster_labels
        )
        
        return visualization
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Erreur lors de la g√©n√©ration de la visualisation {job_id}: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# ===== ENDPOINTS DE SANT√â =====

@app.get("/health")
async def health_check():
    """Point de contr√¥le de sant√© de l'application"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "version": "1.0.0"
    }

@app.get("/api/stats")
async def get_application_stats():
    """Statistiques g√©n√©rales de l'application"""
    try:
        recent_jobs = db_manager.get_recent_jobs(100)
        
        stats = {
            "total_jobs": len(recent_jobs),
            "completed_jobs": len([j for j in recent_jobs if j["status"] == JobStatus.COMPLETED]),
            "failed_jobs": len([j for j in recent_jobs if j["status"] == JobStatus.FAILED]),
            "pending_jobs": len([j for j in recent_jobs if j["status"] == JobStatus.PENDING]),
            "processing_jobs": len([j for j in recent_jobs if j["status"] == JobStatus.PROCESSING])
        }
        
        return stats
        
    except Exception as e:
        logger.error(f"Erreur lors de la r√©cup√©ration des stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 
#!/usr/bin/env python3
"""
Test de simulation des optimisations SERP pour validation des gains de performance
"""

import asyncio
import time
import logging
import random
from typing import List, Dict, Set
from app.services.enrichment import enrichment_service

# Configuration logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SerpSimulator:
    """Simule les appels SERP pour tester les optimisations"""
    
    def __init__(self, base_latency_ms: int = 1500):
        self.base_latency = base_latency_ms / 1000  # Conversion en secondes
        self.call_count = 0
        self.total_time = 0
        
    async def simulate_serp_call(self, keyword: str) -> Set[str]:
        """Simule un appel SERP avec latence r√©aliste"""
        self.call_count += 1
        
        # Simule la latence variable d'un vrai appel API (1-3 secondes)
        latency = self.base_latency + random.uniform(0, 1.0)
        await asyncio.sleep(latency)
        self.total_time += latency
        
        # G√©n√®re des domaines fictifs mais coh√©rents bas√©s sur le mot-cl√©
        domains = set()
        hash_seed = hash(keyword.lower()) % 1000
        
        # Domaines communs pour mots-cl√©s similaires
        common_domains = [
            "amazon.fr", "fnac.com", "cdiscount.com", "darty.com", 
            "boulanger.com", "ldlc.com", "materiel.net", "rueducommerce.fr"
        ]
        
        # S√©lectionne 8-10 domaines de fa√ßon d√©terministe bas√©e sur le mot-cl√©
        random.seed(hash_seed)
        domain_count = random.randint(8, 10)
        selected_domains = random.sample(common_domains, min(domain_count, len(common_domains)))
        
        # Ajoute quelques domaines sp√©cifiques bas√©s sur le mot-cl√©
        if "iphone" in keyword.lower() or "apple" in keyword.lower():
            selected_domains.extend(["apple.com", "iphon.fr"])
        elif "samsung" in keyword.lower():
            selected_domains.extend(["samsung.com", "samsung.fr"])
        elif "ordinateur" in keyword.lower() or "pc" in keyword.lower():
            selected_domains.extend(["grosbill.com", "topachat.com"])
        
        return set(selected_domains[:10])  # Limite √† 10 domaines
    
    def reset_stats(self):
        """Remet √† z√©ro les statistiques"""
        self.call_count = 0
        self.total_time = 0

async def test_serp_performance_simulation():
    """Test complet de simulation des performances SERP"""
    
    print("üß™ SIMULATION DES OPTIMISATIONS SERP")
    print("=" * 60)
    
    # Dataset de test r√©aliste (100 mots-cl√©s e-commerce)
    test_keywords = [
        # Smartphones
        "iphone 14 128gb", "iphone 14 pro", "iphone 13 mini", "samsung galaxy s23", 
        "samsung galaxy s22", "samsung galaxy a54", "pixel 7 pro", "pixel 6a",
        "oneplus 11", "xiaomi 13", "huawei p60", "oppo find x5", "realme gt neo 3",
        
        # Ordinateurs
        "macbook air m2", "macbook pro 14", "dell xps 13", "lenovo thinkpad x1",
        "hp spectre x360", "asus zenbook", "surface laptop 5", "acer swift 3",
        "msi gaming laptop", "alienware x15", "razer blade 15",
        
        # Composants PC
        "rtx 4090", "rtx 4080", "rtx 3080", "radeon rx 7900", "intel i9 13900k",
        "amd ryzen 9 7950x", "ddr5 32gb", "ssd nvme 1tb", "carte m√®re b650",
        
        # P√©riph√©riques
        "clavier m√©canique", "souris gaming", "√©cran 4k 27 pouces", "casque bluetooth",
        "webcam 4k", "micro streaming", "enceinte bluetooth", "tablette graphique",
        
        # √âlectrom√©nager
        "lave linge 9kg", "lave vaisselle 60cm", "r√©frig√©rateur combin√©", "four encastrable",
        "micro ondes grill", "aspirateur robot", "cafeti√®re expresso", "friteuse sans huile",
        
        # TV et Audio
        "tv oled 55 pouces", "tv qled 65 pouces", "barre de son", "home cinema",
        "casque audio", "platine vinyle", "ampli hifi", "enceinte colonne",
        
        # Objets connect√©s
        "montre connect√©e", "bracelet fitness", "cam√©ra surveillance", "thermostat connect√©",
        "ampoule connect√©e", "assistant vocal", "robot aspirateur", "sonnette connect√©e",
        
        # Gaming
        "ps5 console", "xbox series x", "nintendo switch oled", "manette xbox",
        "casque vr", "chaise gaming", "bureau gaming", "√©clairage rgb",
        
        # Bricolage
        "perceuse visseuse", "scie circulaire", "ponceuse orbitale", "niveau laser",
        "multim√®tre", "poste √† souder", "compresseur", "outillage professionnel",
        
        # Sport
        "v√©lo √©lectrique", "trottinette √©lectrique", "home trainer", "montre gps",
        "chaussures running", "sac de sport", "halt√®res", "tapis de course",
        
        # Variations avec prix/tailles
        "iphone 14 256gb", "samsung galaxy s23 128gb", "macbook air 256gb", 
        "√©cran 32 pouces", "ssd 2tb", "ram 16gb", "tv 75 pouces"
    ]
    
    simulator = SerpSimulator(base_latency_ms=1500)  # 1.5s de latence de base
    
    print(f"üìä Dataset de test : {len(test_keywords)} mots-cl√©s")
    print(f"‚è±Ô∏è Latence simul√©e : ~1.5-2.5s par appel SERP")
    print()
    
    # Test 1: Mode S√âQUENTIEL (baseline)
    print("üêå TEST 1: Mode s√©quentiel (ancien comportement)")
    print("-" * 40)
    
    simulator.reset_stats()
    start_time = time.time()
    
    # Simule l'ancien comportement : appels s√©quentiels
    sample_keywords = test_keywords[:20]  # Limite pour le test
    serp_data_sequential = {}
    
    for keyword in sample_keywords:
        domains = await simulator.simulate_serp_call(keyword)
        serp_data_sequential[keyword] = domains
    
    sequential_time = time.time() - start_time
    sequential_calls = simulator.call_count
    
    print(f"‚úÖ Termin√© en {sequential_time:.1f}s")
    print(f"üìû Appels SERP : {sequential_calls}")
    print(f"‚ö° Temps moyen par appel : {sequential_time/sequential_calls:.2f}s")
    print()
    
    # Test 2: Mode PARALL√àLE OPTIMIS√â
    print("üöÄ TEST 2: Mode parall√®le optimis√©")
    print("-" * 40)
    
    simulator.reset_stats()
    start_time = time.time()
    
    # Simule les appels parall√®les avec semaphore
    semaphore = asyncio.Semaphore(10)  # 10 appels parall√®les
    
    async def parallel_scrape(keyword):
        async with semaphore:
            return keyword, await simulator.simulate_serp_call(keyword)
    
    tasks = [parallel_scrape(kw) for kw in sample_keywords]
    results = await asyncio.gather(*tasks)
    
    serp_data_parallel = {kw: domains for kw, domains in results}
    
    parallel_time = time.time() - start_time
    parallel_calls = simulator.call_count
    
    print(f"‚úÖ Termin√© en {parallel_time:.1f}s")
    print(f"üìû Appels SERP : {parallel_calls}")
    print(f"‚ö° Temps moyen par appel : {parallel_time/parallel_calls:.2f}s")
    print(f"üöÄ Gain de vitesse : {sequential_time/parallel_time:.1f}x plus rapide")
    print()
    
    # Test 3: Mode √âCHANTILLONNAGE INTELLIGENT
    print("üß† TEST 3: Mode √©chantillonnage intelligent")
    print("-" * 40)
    
    simulator.reset_stats()
    start_time = time.time()
    
    # Test de la s√©lection intelligente
    full_dataset = test_keywords  # Tous les mots-cl√©s
    selected_keywords = await enrichment_service._smart_keyword_selection(full_dataset)
    
    print(f"üéØ S√©lection intelligente : {len(selected_keywords)}/{len(full_dataset)} mots-cl√©s")
    print(f"üìä R√©duction : {(1 - len(selected_keywords)/len(full_dataset))*100:.0f}%")
    
    # Simule les appels pour les mots-cl√©s s√©lectionn√©s
    tasks = [parallel_scrape(kw) for kw in selected_keywords]
    results = await asyncio.gather(*tasks)
    
    serp_data_smart = {kw: domains for kw, domains in results}
    
    # Simule l'extension de la matrice (plus rapide)
    extension_time = len(full_dataset) * 0.01  # 10ms par mot-cl√© pour l'approximation
    await asyncio.sleep(extension_time)
    
    smart_time = time.time() - start_time
    smart_calls = simulator.call_count
    
    print(f"‚úÖ Termin√© en {smart_time:.1f}s")
    print(f"üìû Appels SERP : {smart_calls}")
    print(f"‚ö° Extension matrice : {extension_time:.1f}s")
    
    # Calcul du gain estim√© pour le dataset complet
    estimated_full_sequential = (len(full_dataset) / len(sample_keywords)) * sequential_time
    smart_speedup = estimated_full_sequential / smart_time
    
    print(f"üìà Gain estim√© (dataset complet) : {smart_speedup:.1f}x plus rapide")
    print()
    
    # Test 4: √âCHANTILLONNAGE + PARALL√âLISATION
    print("‚ö° TEST 4: √âchantillonnage + Parall√©lisation combin√©s")
    print("-" * 40)
    
    simulator.reset_stats()
    start_time = time.time()
    
    # √âchantillonnage agressif (30% des mots-cl√©s)
    sample_size = int(len(full_dataset) * 0.3)
    sampled_keywords = random.sample(full_dataset, sample_size)
    
    # Appels parall√®les sur l'√©chantillon
    tasks = [parallel_scrape(kw) for kw in sampled_keywords]
    results = await asyncio.gather(*tasks)
    
    # Extension rapide
    extension_time = len(full_dataset) * 0.005  # 5ms par mot-cl√©
    await asyncio.sleep(extension_time)
    
    combined_time = time.time() - start_time
    combined_calls = simulator.call_count
    
    print(f"üéØ √âchantillonnage : {len(sampled_keywords)}/{len(full_dataset)} mots-cl√©s (30%)")
    print(f"‚úÖ Termin√© en {combined_time:.1f}s")
    print(f"üìû Appels SERP : {combined_calls}")
    
    # Calcul du gain pour le dataset complet
    combined_speedup = estimated_full_sequential / combined_time
    print(f"üìà Gain estim√© (dataset complet) : {combined_speedup:.1f}x plus rapide")
    print()
    
    # R√âSUM√â FINAL
    print("üìä R√âSUM√â DES PERFORMANCES")
    print("=" * 60)
    print(f"üêå S√©quentiel (baseline)     : {sequential_time:.1f}s pour {len(sample_keywords)} mots-cl√©s")
    print(f"üöÄ Parall√®le                 : {parallel_time:.1f}s ({sequential_time/parallel_time:.1f}x plus rapide)")
    print(f"üß† S√©lection intelligente    : {smart_time:.1f}s ({smart_speedup:.1f}x plus rapide estim√©)")
    print(f"‚ö° √âchantillonnage + Parall√®le: {combined_time:.1f}s ({combined_speedup:.1f}x plus rapide estim√©)")
    print()
    print("üí° RECOMMANDATIONS:")
    print(f"‚Ä¢ Pour <500 mots-cl√©s  : Parall√©lisation simple (10-20 appels concurrents)")
    print(f"‚Ä¢ Pour 500-2000 m-c    : S√©lection intelligente + parall√©lisation")
    print(f"‚Ä¢ Pour >2000 mots-cl√©s : √âchantillonnage 30% + parall√©lisation")
    print()
    
    # Test de qualit√© des r√©sultats
    print("üéØ QUALIT√â DES R√âSULTATS")
    print("=" * 30)
    
    # Compare la coh√©rence entre modes
    common_kw = set(serp_data_sequential.keys()) & set(serp_data_parallel.keys())
    if len(common_kw) >= 2:
        similarities_seq = []
        similarities_par = []
        
        for kw1 in list(common_kw)[:5]:
            for kw2 in list(common_kw)[:5]:
                if kw1 != kw2:
                    # Calcule similarit√© Jaccard
                    domains1_seq = serp_data_sequential[kw1]
                    domains2_seq = serp_data_sequential[kw2]
                    sim_seq = len(domains1_seq & domains2_seq) / len(domains1_seq | domains2_seq)
                    similarities_seq.append(sim_seq)
                    
                    domains1_par = serp_data_parallel[kw1]
                    domains2_par = serp_data_parallel[kw2]
                    sim_par = len(domains1_par & domains2_par) / len(domains1_par | domains2_par)
                    similarities_par.append(sim_par)
        
        if similarities_seq and similarities_par:
            avg_diff = sum(abs(s - p) for s, p in zip(similarities_seq, similarities_par)) / len(similarities_seq)
            print(f"üìä Diff√©rence moyenne s√©quentiel vs parall√®le : {avg_diff:.4f}")
            
            if avg_diff < 0.02:
                print("‚úÖ Qualit√© pr√©serv√©e - r√©sultats tr√®s coh√©rents")
            elif avg_diff < 0.05:
                print("‚úÖ Qualit√© acceptable - l√©g√®res variations")
            else:
                print("‚ö†Ô∏è Qualit√© d√©grad√©e - variations importantes")

if __name__ == "__main__":
    asyncio.run(test_serp_performance_simulation()) 